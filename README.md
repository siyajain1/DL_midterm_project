# DL_midterm_project

This repository contains our solution for the DL-Fall-25 Kaggle Competition, where the goal is to fine-tune the Llama-3-8B model (Supervised Fine-Tuning, SFT) to predict whether an answer to a math question is correct or incorrect.
We achieved strong results by combining prompt engineering, LoRA fine-tuning, and systematic hyperparameter optimization to maximize accuracy.

### ğŸš€ Project Overview
Task: Binary classification â€” determine if a math questionâ€™s answer is correct.

Model: Llama-3-8B (Supervised Fine-Tuning)

Dataset: Provided competition training set only

Frameworks: PyTorch, Hugging Face Transformers, PEFT (LoRA)
Submission Format: CSV with columns ID and is_correct

### ğŸ§‘â€ğŸ’» Team
Siya Jain sj3439@nyu.edu

Zihao Li zl2946@nyu.edu
